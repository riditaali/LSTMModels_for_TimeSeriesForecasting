{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/"
      ],
      "metadata": {
        "id": "NcO9BM50EweX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Univariate LSTM Models: Bidirectional LSTM**"
      ],
      "metadata": {
        "id": "lTr4EjntmqMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Bidirectional LSTM: Sometimes, it's beneficial to allow the LSTM model to learn the input sequence both forward and backwards and concatenate both interpretations.*"
      ],
      "metadata": {
        "id": "RMU0ZbIKLunc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation: A Bidirectional LSTM for univariate time series forecasting by wrapping the first hidden layer in a wrapper layer called Bidirectional."
      ],
      "metadata": {
        "id": "jcm9SgH3nrd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### import libraries\n",
        "\n",
        "from numpy import array\n",
        "\n",
        "# univariate lstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Bidirectional"
      ],
      "metadata": {
        "id": "zROK7FtmHR6N"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###split_sequence() function =\n",
        "###above behaviour =\n",
        "### if n_steps are chosen as 3 then three numbers are selected as inputs and the fourth number is selected as output and again this repeated\n",
        "\n",
        "def split_sequence(sequence, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)"
      ],
      "metadata": {
        "id": "LDnnTlAwGF9O"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)"
      ],
      "metadata": {
        "id": "k-psmWbrHfEE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))"
      ],
      "metadata": {
        "id": "_VufNBtqJujy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#a Bidirectional LSTM for univariate time series forecasting\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipLwiazIKk_H",
        "outputId": "90187c06-2c89-4a16-eeaa-9a4f508cb5da"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model\n",
        "model.fit(X, y, epochs=200, verbose=0) #epoch: the number of complete passes through the training dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSrrrQGmKaYR",
        "outputId": "5a2794cb-3d52-431f-f8c8-d91681541acc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7875a2fa60e0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# demonstrate prediction\n",
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat) #the model predicts the next value in the sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulUeqT4sLQNk",
        "outputId": "92cdd4b4-8142-4ec3-d439-db199f5a2fed"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[101.61346]]\n"
          ]
        }
      ]
    }
  ]
}